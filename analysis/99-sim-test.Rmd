---
title: Simulation testing
---

```{r packages, message=FALSE, warning=FALSE, results='hide'}
library(rstan)
library(ggplot2)
library(dplyr)
library(viridisLite)
library(here)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
theme_set(ggsidekick::theme_sleek())
```

# The model

Building on the model from the appendix section *Estimating regional trends in abundance, fishing pressure and catch* of the paper [*Effective fisheries management instrumental in improving fish stock status*](https://doi.org/10.1073/pnas.1909726116)...

The model is currently:

$$
x_t = x_{t-1} + \eta_t, \; 
      \eta_t \sim \mathrm{Normal} 
      \left( 0, \sigma_{\eta}^2 \right),
$$
where $x_t$ is the underlying overall *log* stock status state/process at time $t$ and $\eta_t$ is a random walk deviation with standard deviation $\sigma_\eta$.

We use the auto-regressive observation model:

$$
\begin{align}
\hat{y}_{j,t} &\sim \mathrm{Normal} \left( y_{j,t}, \tau^2\right)\\
y_{j,t} &= x_{t} + \alpha_j + \epsilon_{j,t}, \; 
      \epsilon_{j,t} \sim \mathrm{Normal} 
      \left(\varphi \epsilon_{j,t-1}, \sigma_{\epsilon}^2 \right),
\end{align}
$$
where $\hat{y}_{j,t}$ is the mean log stock status (e.g., biomass divided by biomass at the Limit Reference Point) for stock $j$ and time $t$, $y_{j,t}$ is the true unobserved stock-specific status, and $\tau$ is the standard error on the mean log stock-specific status from the assessment (i.e., this is a measurement error component).
The symbol $\alpha_j$ represents a stock specific intercept that is constrained such that the sum of all $\alpha_j$ is zero to make the model identifiable (i.e., a "random intercept" with infinite variance). This could instead be constrained to vary taxonomically. The symbol $\epsilon_{j,t}$ represents an AR1 deviation with correlation $\varphi$ and standard deviation $\sigma_\epsilon$.

We place priors on all parameters, including on the initial state and observation (not shown yet).

# Simulating data

The following is a function to simulate some data from our model:

```{r}
sim_dat <- function(sigma_x = 0.3, sigma_eps = 0.8, n_j = 20,
                    n_t = 40, rho = 0.8, alpha_sd = 0.5,
                    tau = 0.2) {
  a_j <- rnorm(n_j, 0, alpha_sd)
  a_j <- a_j - mean(a_j) # sum to zero
  x_t <- numeric(length = n_t)
  x_t[1] <- rnorm(1, 0, sigma_x)
  for (i in seq(2, n_t)) {
    x_t[i] <- x_t[i - 1] + rnorm(1, 0, sigma_x)
  }
  y_jt <- matrix(ncol = n_j, nrow = n_t)
  eps_jt <- matrix(ncol = n_j, nrow = n_t)
  for (i in seq_len(n_t)) {
    for (j in seq_len(n_j)) {
      if (i == 1L) {
        eps_jt[i, j] <- rnorm(1, 0, sigma_eps)
      } else {
        eps_jt[i, j] <- rnorm(1, rho * eps_jt[i - 1, j], sigma_eps)
      }
      y_jt[i, j] <- x_t[i] + a_j[j] + eps_jt[i, j]
    }
  }
  list(
    x_t = x_t,
    y_true = y_jt,
    y = y_jt + rnorm(length(as.numeric(y_jt)), 0, tau),
    tau = matrix(tau, nrow = nrow(y_jt), ncol = ncol(y_jt)),
    alpha = a_j,
    rho = rho,
    sigma_eps = sigma_eps,
    sigma_x = sigma_x
  )
}
```

Apply our simulation function:

```{r}
set.seed(42)
d <- sim_dat(
  sigma_x = 0.3,
  sigma_eps = 0.5,
  n_j = 12,
  n_t = 50,
  rho = 0.7
)
```

Artificially remove some data to reflect assessments on some stocks not starting in the first year an some assessments being old.

Note that we use a trick of `999` being a "magic" number in Stan since Stan can't work with NAs itself. There are other options that would be slightly faster, but this makes for simple code.

```{r}
d$y[1:20, 1:9] <- NA
d$y[40:50, 9:12] <- NA
d$y_true[1:20, 1:9] <- NA
d$y_true[40:50, 9:12] <- NA
d$y_999 <- d$y
d$y_999[is.na(d$y)] <- 999 # fake NA
dat <- list(
  T = nrow(d$y_999),
  J = ncol(d$y_999),
  y = d$y_999,
  tau = d$tau,
  # df = 7,
  s = rep(nrow(d$y), ncol(d$y))
)
```

A plot of our simulated data. The first panel reflects the observed mean stock status and the second panel reflects the underlying "true" stock status. We need to think of a better term, since it's not really the "true" stock status but the latent stock status underlying the estimated mean and SD. The black line is the overall trend status.

```{r}
par(mfrow = c(1, 2))
matplot(d$y, type = "l", lty = 1, col = plasma(ncol(d$y)))
lines(seq_along(d$x_t), (d$x_t), lwd = 3)
matplot(d$y_true, type = "l", lty = 1, col = plasma(ncol(d$y)))
lines(seq_along(d$x_t), (d$x_t), lwd = 3)
```

The Stan model:

```{r}
writeLines(readLines(here("analysis/rw-ss.stan")))
```

There are a number of "tricks" built into the model to enable efficient sampling including "non-centered parameterizations" of various variance terms.

Compile the model:

```{r compile-model, warning=FALSE, message=FALSE, results="hide", cache=TRUE}
model <- stan_model(here("analysis/rw-ss.stan"))
```

Set up a custom initialization function and sample from the model:

```{r fit-model, warning=FALSE, message=FALSE, results="hide", cache=TRUE}
initf <- function() {
  list(
    rho = runif(1, 0.2, 0.7),
    sigma_eps = runif(1, 0.1, 0.5),
    sigma_x = runif(1, 0.1, 0.5)
  )
}
m <- sampling(
  model,
  data = dat,
  chains = 8, iter = 1000, seed = 1823,
  control = list(adapt_delta = 0.95),
  pars = c("rho", "sigma_eps", "sigma_x", "x", "alpha"),
  init = initf
)
```

Inspect the model:

```{r basic-plots, cache=TRUE}
pairs(m, pars = c("sigma_eps", "sigma_x", "rho", "x[1]", "alpha[1]"))
rstan::check_hmc_diagnostics(m)
# rstan::stan_rhat(m)
# rstan::stan_diag(m)
print(m, pars = c("sigma_eps", "sigma_x", "rho", "alpha"))
# shinystan::launch_shinystan(m)
```

Look at the posterior distributions:

```{r}
p <- extract(m)
# p <- tidybayes::gather_draws(m, alpha[.j], x[.t], sigma_eps, sigma_x, rho)

par(mfrow = c(2, 3))
matplot(d$y, type = "l", lty = 1, col = viridisLite::plasma(ncol(d$y)))
lines(seq_along(d$x_t), (d$x_t), lwd = 3)

plot(d$alpha, colMeans(p$alpha), asp = 1)
lwr <- apply(p$alpha, 2, quantile, probs = 0.05)
upr <- apply(p$alpha, 2, quantile, probs = 0.95)
segments(x0 = d$alpha, y0 = lwr, y1 = upr)
abline(a = 0, b = 1)
cat("alpha_j 90% CI coverage:", mean(lwr < d$alpha & upr > d$alpha), "\n")

plot(d$x, colMeans(p$x), asp = 1)
lwr <- apply(p$x, 2, quantile, probs = 0.05)
upr <- apply(p$x, 2, quantile, probs = 0.95)
segments(x0 = d$x, y0 = lwr, y1 = upr)
abline(a = 0, b = 1)
cat("x_t 90% CI coverage:", mean(lwr < d$x & upr > d$x), "\n")

hist(p$rho)
abline(v = d$rho, col = "red")
hist(p$sigma_eps)
abline(v = d$sigma_eps, col = "red")
hist(p$sigma_x)
abline(v = d$sigma_x, col = "red")
```

Look at the estimated overall trend (grey/black) and the true overall trend (red):

```{r}
x_t <- tidybayes::gather_draws(m, x[.t])
x_t %>%
  group_by(.t) %>%
  summarize(
    lwr2 = quantile(.value, 0.975),
    upr2 = quantile(.value, 0.025),
    lwr1 = quantile(.value, 0.25),
    upr1 = quantile(.value, 0.75),
    lwr = quantile(.value, 0.1),
    upr = quantile(.value, 0.9),
    med = median(.value), .groups = "drop"
  ) %>%
  ggplot(aes(.t, med)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.25) +
  geom_ribbon(aes(ymin = lwr1, ymax = upr1), alpha = 0.25) +
  geom_ribbon(aes(ymin = lwr2, ymax = upr2), alpha = 0.25) +
  geom_line() +
  geom_line(
    data =
      data.frame(.t = seq_along(d$x), med = d$x), colour = "red", lwd = 1
  )
```
